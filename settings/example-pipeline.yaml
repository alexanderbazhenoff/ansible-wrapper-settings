---

# Example settings for 'universal wrapper pipeline' with maximum number of possible features and parameters.

# Please also read the detailed settings format documentation.
# English: https://github.com/alexanderbazhenoff/universal-wrapper-pipeline-settings/blob/main/README.md
# Russian: https://github.com/alexanderbazhenoff/universal-wrapper-pipeline-settings/blob/main/README_RUS.md


# Copyright (c) 2023 Alexander Bazhenov.
#
# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
# documentation files (the "Software"), to deal in the Software without restriction, including without limitation the
# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit
# persons to whom the Software is furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the
# Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
# OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


parameters:
  # Required parameters dictionary inside, but empty `EMAIL` parameter will not fail the whole pipeline. Also, the empty
  # `SSH_SUDO_PASSWORD` will be assigned from `SSH_PASSWORD` parameter.
  required:
    # Host list in `IP_ADDRESSES` will be split by newline instead of spaces (see `regex_replace`).
    - name: IP_ADDRESSES
      type: string
      description: Space separated IP or DNS list of the host(s) to perform PIPELINE_ACTION and ROLE_SUBJECT.
      regex_replace:
        regex: ' '
        to: \n
    # `SSH_LOGIN` value will be checked on regex match.
    - name: SSH_LOGIN
      type: string
      regex: ^[a-z_]([a-z0-9_-]{0,31}|[a-z0-9_-]{0,30}\$)$
      description: Login for SSH connection for install/uninstall components and copy configs (The same for all hosts).
    - name: SSH_PASSWORD
      type: password
      description: SSH password for install/uninstall components and copy configs (The same for all hosts).
    # When `SSH_SUDO_PASSWORD` is empty not fail pipeline and print warning, just assign value from `SSH_LOGIN`.
    - name: SSH_SUDO_PASSWORD
      type: password
      description: |
        SSH sudo password or root password for install/uninstall components and copy configs (The same for all hosts).
        If this parameter is empy SSH_PASSWORD will be used.
      on_empty:
        assign: $SSH_PASSWORD
        fail: False
    # Define action by choices of `PIPELINE_ACTION`. Using spaces in action and stage names are allowed.
    - name: PIPELINE_ACTION
      type: choice
      choices:
        - install lxc action name
        - show ansible hostname action name
        - run downstream job action name
    # Just warn and not do not fail the whole pipeline when `EMAIL` value is empty. Regular expression defined as a
    # list, which will be merged into a huge string.
    - name: EMAIL
      type: string
      default: my-email@domain.net
      on_empty:
        warn: True
      regex:
        - '(?:(?:\r\n)?[ \t])*(?:(?:(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t]'
        - ')+|\Z|(?=[\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:'
        - '\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:('
        - '?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ '
        - '\t]))*"(?:(?:\r\n)?[ \t])*))*@(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\0'
        - '31]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\'
        - '](?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+'
        - '(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:'
        - '(?:\r\n)?[ \t])*))*|(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z'
        - '|(?=[\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)'
        - '?[ \t])*)*\<(?:(?:\r\n)?[ \t])*(?:@(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\'
        - 'r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?['
        - ' \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)'
        - '?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t]'
        - ')*))*(?:,@(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?['
        - ' \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*'
        - ')(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t]'
        - ')+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*))*)'
        - '*:(?:(?:\r\n)?[ \t])*)?(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+'
        - '|\Z|(?=[\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r'
        - '\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:'
        - '\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t'
        - ']))*"(?:(?:\r\n)?[ \t])*))*@(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031'
        - ']+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\]('
        - '?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?'
        - ':(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?'
        - ':\r\n)?[ \t])*))*\>(?:(?:\r\n)?[ \t])*)|(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?'
        - ':(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?'
        - '[ \t]))*"(?:(?:\r\n)?[ \t])*)*:(?:(?:\r\n)?[ \t])*(?:(?:(?:[^()<>@,;:\\".\[\] '
        - '\000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|'
        - '\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>'
        - '@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|"'
        - '(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t])*))*@(?:(?:\r\n)?[ \t]'
        - ')*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\'
        - '".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?'
        - ':[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\['
        - '\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*))*|(?:[^()<>@,;:\\".\[\] \000-'
        - '\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\.|('
        - '?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t])*)*\<(?:(?:\r\n)?[ \t])*(?:@(?:[^()<>@,;'
        - ':\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[(['
        - '^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\"'
        - '.\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\'
        - ']\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*))*(?:,@(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\'
        - '[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\'
        - 'r\\]|\\.)*\](?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] '
        - '\000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]'
        - '|\\.)*\](?:(?:\r\n)?[ \t])*))*)*:(?:(?:\r\n)?[ \t])*)?(?:[^()<>@,;:\\".\[\] \0'
        - '00-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\'
        - '.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,'
        - ';:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|"(?'
        - ':[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t])*))*@(?:(?:\r\n)?[ \t])*'
        - '(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".'
        - '\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:['
        - '^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]'
        - ']))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*))*\>(?:(?:\r\n)?[ \t])*)(?:,\s*('
        - '?:(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\'
        - '".\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t])*)(?:\.(?:('
        - '?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=['
        - '\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t'
        - '])*))*@(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t'
        - '])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*)(?'
        - ':\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|'
        - '\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*))*|(?:'
        - '[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\'
        - ']]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t])*)*\<(?:(?:\r\n)'
        - '?[ \t])*(?:@(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["'
        - '()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)'
        - '?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>'
        - '@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*))*(?:,@(?:(?:\r\n)?['
        - ' \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,'
        - ';:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t]'
        - ')*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\'
        - '".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*))*)*:(?:(?:\r\n)?[ \t])*)?'
        - '(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".'
        - '\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t])*)(?:\.(?:(?:'
        - '\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\['
        - '"()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t])'
        - '*))*@(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])'
        - '+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*)(?:\'
        - '.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z'
        - '|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*))*\>(?:('
        - '?:\r\n)?[ \t])*))*)?;\s*)'
      description: Email to send report.

  optional:
    # Obviously, if boolean parameters are already injected to pipeline it will always be defined. So you don't need to
    # set them as 'required'. These parameters are also less significant. So it's ok to add them after 'required'
    # parameters, which are always injected first on pipeline parameters update.
    - name: PERFORM_PING
      type: boolean
      default: False
      description: Perform ansible ping.
    - name: LXCFS
      type: boolean
      default: False
      description: Install lxcfs instead of lxc.


stages:
  - name: stage_1
  # Spaces in stage and action names are also allowed.
    actions:
      # Clone sources, install ansible galaxy collection, action defined in `PIPELINE_ACTION` variable, stash files,
      # unstash on node with label `ansible29` then finally archive artifacts on the same node. Actions are sequential.
      - before_message: Clone sources to make an artifacts just for example
        action: git_clone_action_name
      # Take a look at before, after, fail and success messages.
      - action: ansible_galaxy_install_action_name
        after_message: Installing collection to run lxfs ansible role done.
        fail_message: Executing ansible playbook failed.
        success_message: Executing ansible playbook finished.
      - action: $PIPELINE_ACTION
      - action: stash files action name
      # When you change the node from pipeline start node, you should set node for every action. Otherwise, the
      # execution returns to the start node.
      - action: unstash files action name
        node:
          label: ansible29
      - action: action archive artifacts action name
        node:
          label: ansible29

  - name: stage_2
    # Actions in this (scripts and reports) stage will start in parallel.
    parallel: True
    actions:
      - action: run custom code as a part of pipeline action name
      - action: run bash script action name
      - action: email report action name
      - action: mattermost report action name


  - name: stage_3
    actions:
      # All errors in this action will be ignored.
      - before_message: Running final action with exit code 1...
        action: run bash final script action name
        ignore_fail: True


# All possible kinds of actions set here.
actions:
  # Clone sources to `subdirectory_in_workspace_for_repository` then switch to the `main` branch.
  git_clone_action_name:
    repo_url: https://github.com/alexanderbazhenoff/ansible-collection-linux.git
    repo_branch: main
    directory: subdirectory_in_workspace_for_repository

  # Install an ansible collection from Ansible Galaxy.
  ansible_galaxy_install_action_name:
    collection: alexanderbazhenoff.linux

  # Actions that run ansible playbooks.
  install_lxc_action_name:
    playbook: ping_playbook_name

  show ansible hostname action name:
    playbook: run_role_playbook_name

  # Run downstream `name_of_pipeline` and pass `DOWNSTREAM_JOB_PARAMETER_1` with `PERFORM_PING` upstream pipeline
  # parameter value and `EMAIL` with `EMAIL` value. Do not propagate errors of a downstream pipeline, but wait for the
  # completion. Finally, copy `test_file.txt` from `downstream_job_artifacts_folder_name` folder in workspace of
  # `name_of_pipeline` as artifacts, but ignore when this file is absent. No fingerprints.
  run downstream job action name:
    pipeline: name_of_pipeline
    parameters:
      # Take a look at value pass: you should pass a value as `$FOO` for boolean parameter. Otherwise, pass as a `$BAR`
      # or `${BAR}`.
      - name: DOWNSTREAM_JOB_PARAMETER_1
        type: boolean
        value: $PERFORM_PING
      - name: EMAIL
        type: string
        value: ${EMAIL}
    propagate: False
    copy_artifacts:
      filter: test_file.txt
      fingerprint: True
      target_directory: downstream_job_artifacts_folder_name
      optional: True

  # Stash any file in any sub-directory of `subdirectory_in_workspace_for_repository` folder in workspace with
  # `stash_name` naming.
  stash files action name:
    stash: stash_name
    includes: subdirectory_in_workspace_for_repository/**/*

  # Unstash files and folders with stash name `stash_name`.
  unstash files action name:
    unstash: stash_name

  # Archive as pipeline artifact any file from cloned from a git ansible collection, including unexisting file
  # `test_file.txt`, but except markdown files inside the roles. Do not fail the whole pipeline execution on unexisting
  # `test_file.txt` file.
  action archive artifacts action name:
    artifacts: subdirectory_in_workspace_for_repository/**/roles/*, test_file.txt
    excludes: subdirectory_in_workspace_for_repository/**/roles/*.md
    allow_empty: True

  # Actions to run scripts.
  run custom code as a part of pipeline action name:
    script: script_name_1

  run bash script action name:
    script: script_name_2

  # Action that sends email report with a name of the pipeline, overall pipeline status, URL to console and
  # stages and actions report table.
  email report action name:
    report: email
    to: ${env.EMAIL}
    reply_to: ${env.EMAIL}
    subject: Test email report
    body: |
      Hi,
      
      I've just run a test for universal jenkins wrapper pipeline for '${env.JOB_NAME}' pipeline, finished with
      '${currentBuild.result}' state. As you see sending report to ${env.EMAIL} done.
      
      Overall report is:
      ${universalPipelineWrapperBuiltIns.multilineReport}
      
      Check pipeline console for details: ${env.BUILD_URL}/console
      This report was generated automatically, please do not reply.
      
      Sincerely,
      Your Jenkins.

  # Action that sends mattermost report to mattermost.com using token with pipeline name and stages and actions report
  # table.
  mattermost report action name:
    report: mattermost
    # So paste your mattermost URL and working token like this, or set as global variable inside the libraries
    # (then set something like `${GlobalVariable}`).
    url: https://mattermost.com/hooks/31895e09lg2m0g44dk4qeb847s
    text: |
      Hi, I've just run a test for universal jenkins wrapper pipeline: ${env.JOB_NAME}.
      Overall report is:
      ```
      ${universalPipelineWrapperBuiltIns.multilineReport}
      ```
      Please ignore this automatic report.

  # Run a final script that exits with error (but this will be ignored by setting up the key `ignore_fail` in `stages`.
  run bash final script action name:
    script: script_name_3


# All possible kinds of script running here.
scripts:

  # Run a code as a part of pipeline including code for Jenkins and Teamcity that will be selected in the appropriate
  # environment.
  script_name_1:
    pipeline: True
    jenkins: |
      // some groovy code here to print 'PIPELINE_ACTION' and 'EMAIL' pipeline parameters:
      println String.format('EMAIL provided for %s action is awesome: %s', env.PIPELINE_ACTION, env.EMAIL)
    teamcity: |
      // some kotlin code here to print 'PIPELINE_ACTION' and 'EMAIL' pipeline parameters:
      print (String.format("EMAIL provided for %s action is awesome: %s", env.PIPELINE_ACTION, env.EMAIL))
  script_name_2:
    # You can also set `#!/usr/bin/env python` hashbang.
    script: |
      #!/usr/bin/env bash
      printf "Here is some output of LXCFS environment variable, which also a pipeline parameter: %s\n" "$LXCFS"
      printf "while the whole environment variables looks like: %s\n" "$(env)"

  script_name_3:
    script: |
      #!/usr/bin/env bash
      echo "All done, but exit 1."
      exit 1


# Playbooks are here, where ansible ping will be skipped when `PERFORM_PING` pipeline parameter wasn't set.
playbooks:

  ping_playbook_name: |
    - hosts: all

      tasks:

        - name: "Perform ansible ping on the host(s)"
          ansible.builtin.ping:
          when: $PERFORM_PING

  run_role_playbook_name: |
    - hosts: all
      become: True
      become_method: sudo
      gather_facts: True

      tasks:

        - name: "Ping host(s)"
          ansible.builtin.ping:
          when: $PERFORM_PING

        - name: "Install lxc(fs)"
          ansible.builtin.include_role:
            name: alexanderbazhenoff.linux.lxcfs
          vars:
            lxc_technology: {{ $LXCFS | ternary ('lxcfs', 'lxc') }}

# The only inventory for both playbooks is here.
inventories:

  default: |
    [all]
    $IP_ADDRESSES

    [all:vars]
    ansible_connection=ssh
    ansible_become_user=root
    ansible_ssh_common_args='-o StrictHostKeyChecking=no'
    ansible_ssh_user=$SSH_LOGIN
    ansible_ssh_pass=$SSH_PASSWORD
    ansible_become_pass=$SSH_SUDO_PASSWORD
