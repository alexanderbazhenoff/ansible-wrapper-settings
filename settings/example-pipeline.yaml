---

# Example settings for 'universal wrapper pipeline' with maximum number of possible features and parameters.

# Please also read the detailed settings format documentation.
# English: https://github.com/alexanderbazhenoff/universal-wrapper-pipeline-settings/blob/main/README.md
# Russian: https://github.com/alexanderbazhenoff/universal-wrapper-pipeline-settings/blob/main/README_RUS.md


# Copyright (c) 2023 Alexander Bazhenov.
#
# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated
# documentation files (the "Software"), to deal in the Software without restriction, including without limitation the
# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit
# persons to whom the Software is furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the
# Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
# OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


parameters:
  # Required parameters dictionary inside, but empty `EMAIL` parameter will not fail the whole pipeline. Also, the empty
  # `SSH_SUDO_PASSWORD` will be assigned from `SSH_PASSWORD` parameter.
  required:
    # Host list in `IP_ADDRESSES` will be split by newline instead of spaces (see `regex_replace`).
    - name: IP_ADDRESSES
      type: string
      description: Space separated IP or DNS list of the host(s) to perform PIPELINE_ACTION and ROLE_SUBJECT.
      regex_replace:
        regex: ' '
        to: \n
    # `SSH_LOGIN` value will be checked on regex match.
    - name: SSH_LOGIN
      type: string
      regex: ^[a-z_]([a-z0-9_-]{0,31}|[a-z0-9_-]{0,30}\$)$
      description: Login for SSH connection for install/uninstall components and copy configs (The same for all hosts).
    - name: SSH_PASSWORD
      type: password
      description: SSH password for install/uninstall components and copy configs (The same for all hosts).
    # When `SSH_SUDO_PASSWORD` is empty not fail pipeline and print warning, just assign value from `SSH_LOGIN`.
    - name: SSH_SUDO_PASSWORD
      type: password
      description: |
        SSH sudo password or root password for install/uninstall components and copy configs (The same for all hosts).
        If this parameter is empy SSH_PASSWORD will be used.
      on_empty:
        assign: $SSH_PASSWORD
        fail: False
    # Define action by choices of `PIPELINE_ACTION`. Using spaces in action and stage names are allowed.
    - name: PIPELINE_ACTION
      type: choice
      choices:
        - install lxc action name
        - show ansible hostname action name
        - run downstream job with artifacts action name
    # Just warn and not do not fail the whole pipeline when `EMAIL` value is empty. Regular expression defined as a
    # list, which will be merged into a huge string. You can also split parameters blocks using several `<br>` at the
    # end of description value.
    - name: EMAIL
      type: string
      default: my-email@domain.net
      on_empty:
        warn: True
      regex:
        - '(?:(?:\r\n)?[ \t])*(?:(?:(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t]'
        - ')+|\Z|(?=[\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:'
        - '\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:('
        - '?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ '
        - '\t]))*"(?:(?:\r\n)?[ \t])*))*@(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\0'
        - '31]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\'
        - '](?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+'
        - '(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:'
        - '(?:\r\n)?[ \t])*))*|(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z'
        - '|(?=[\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)'
        - '?[ \t])*)*\<(?:(?:\r\n)?[ \t])*(?:@(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\'
        - 'r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?['
        - ' \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)'
        - '?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t]'
        - ')*))*(?:,@(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?['
        - ' \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*'
        - ')(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t]'
        - ')+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*))*)'
        - '*:(?:(?:\r\n)?[ \t])*)?(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+'
        - '|\Z|(?=[\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r'
        - '\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:'
        - '\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t'
        - ']))*"(?:(?:\r\n)?[ \t])*))*@(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031'
        - ']+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\]('
        - '?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?'
        - ':(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?'
        - ':\r\n)?[ \t])*))*\>(?:(?:\r\n)?[ \t])*)|(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?'
        - ':(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?'
        - '[ \t]))*"(?:(?:\r\n)?[ \t])*)*:(?:(?:\r\n)?[ \t])*(?:(?:(?:[^()<>@,;:\\".\[\] '
        - '\000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|'
        - '\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>'
        - '@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|"'
        - '(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t])*))*@(?:(?:\r\n)?[ \t]'
        - ')*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\'
        - '".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?'
        - ':[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\['
        - '\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*))*|(?:[^()<>@,;:\\".\[\] \000-'
        - '\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\.|('
        - '?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t])*)*\<(?:(?:\r\n)?[ \t])*(?:@(?:[^()<>@,;'
        - ':\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[(['
        - '^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\"'
        - '.\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\'
        - ']\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*))*(?:,@(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\'
        - '[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\'
        - 'r\\]|\\.)*\](?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] '
        - '\000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]'
        - '|\\.)*\](?:(?:\r\n)?[ \t])*))*)*:(?:(?:\r\n)?[ \t])*)?(?:[^()<>@,;:\\".\[\] \0'
        - '00-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\'
        - '.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,'
        - ';:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|"(?'
        - ':[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t])*))*@(?:(?:\r\n)?[ \t])*'
        - '(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".'
        - '\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t])*(?:['
        - '^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\]'
        - ']))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*))*\>(?:(?:\r\n)?[ \t])*)(?:,\s*('
        - '?:(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\'
        - '".\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t])*)(?:\.(?:('
        - '?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=['
        - '\["()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t'
        - '])*))*@(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t'
        - '])+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*)(?'
        - ':\.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|'
        - '\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*))*|(?:'
        - '[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".\[\'
        - ']]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t])*)*\<(?:(?:\r\n)'
        - '?[ \t])*(?:@(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["'
        - '()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)'
        - '?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>'
        - '@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*))*(?:,@(?:(?:\r\n)?['
        - ' \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,'
        - ';:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*)(?:\.(?:(?:\r\n)?[ \t]'
        - ')*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\'
        - '".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*))*)*:(?:(?:\r\n)?[ \t])*)?'
        - '(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\["()<>@,;:\\".'
        - '\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t])*)(?:\.(?:(?:'
        - '\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z|(?=[\['
        - '"()<>@,;:\\".\[\]]))|"(?:[^\"\r\\]|\\.|(?:(?:\r\n)?[ \t]))*"(?:(?:\r\n)?[ \t])'
        - '*))*@(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])'
        - '+|\Z|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*)(?:\'
        - '.(?:(?:\r\n)?[ \t])*(?:[^()<>@,;:\\".\[\] \000-\031]+(?:(?:(?:\r\n)?[ \t])+|\Z'
        - '|(?=[\["()<>@,;:\\".\[\]]))|\[([^\[\]\r\\]|\\.)*\](?:(?:\r\n)?[ \t])*))*\>(?:('
        - '?:\r\n)?[ \t])*))*)?;\s*)'
      description: Email to send report.<br><br><br><br>
    - name: DOWNSTREAM_PIPELINE_NAME
      type: string
      default: downstream-example-pipeline
      description: Downstream pipeline name.<br><br><br><br>


  optional:
    # Obviously, if boolean parameters are already injected to pipeline it will always be defined. So you don't need to
    # set them as 'required'. These parameters are also less significant. So it's ok to add them after 'required'
    # parameters, which are always injected first on pipeline parameters update.
    - name: PERFORM_PING
      type: boolean
      default: False
      description: Perform ansible ping.
    - name: LXCFS
      type: boolean
      default: False
      description: Install lxcfs instead of lxc.<br><br><br><br>


stages:
  - name: stage_1
  # Spaces in stage and action names are also allowed.
    actions:
      # Clone sources, install ansible galaxy collection, action defined in `PIPELINE_ACTION` variable, stash files,
      # unstash on node with label `ansible29` then finally archive artifacts on the same node. Actions are sequential.
      # Pipeline build name will be formed from action, email and current build number. This action sources will be
      # cloned to `sources` subdirectory.
      - before_message: Clone sources to make an artifacts just for example
        action: git_clone_action_name
        build_name: $PIPELINE_ACTION-$EMAIL--#$BUILD_NUMBER
      # Take a look at before, after, fail and success messages.
      - action: ansible_galaxy_install_action_name
        after_message: Installing collections to run lxfs ansible role done.
        fail_message: Installing ansible collections failed.
        success_message: Installing ansible collections finished.
        stop_on_fail: True
      - before message: |
          Install community.docker collection just fo example of sing collection install, because it's not required.
        action: ansible_galaxy_install_action_name_2
      - action: $PIPELINE_ACTION
      - action: stash files action name
      # When you change the node from pipeline start node, you should set node for every action. Otherwise, the
      # execution returns to the start node.
      - action: unstash files action name
        node:
          label: ansible29
      - action: archive artifacts action name
        node:
          label: ansible29

  - name: stage_2
    # Actions in this stage will start in parallel.
    parallel: True
    actions:
      - action: run custom code as a part of pipeline action name
      - action: run bash script action name
      - before_message: Archive additional artifacts...
        action: archive additional artifacts action name
        success_message: Additional artifacts was successfully archived.
        dir: settings

  - name: stage_3
    actions:
      # All errors in the first action will be ignored. Take a look at conditions and messages in other actions.
      - before_message: Running action with exit code 1 on any node...
        action: run bash final script action name
        ignore_fail: True
        node:
      - before_message: |
          This action will never run because requires at least one action with fail, but all completed with SUCCESS.
        action: run bash final script action name
        fail_only: True
      # Take a look at 'node' key: you can specify them by 'node' sub-key or just as string value of a node key.
      - before_message: This action will run on master node only when all actions completed with SUCCESS...
        action: run bash final script action name
        success_only: True
        node: master
      - before_message: |
          This action will never run because requires all actions completed with SUCCESS, but previous was failed.
        action: run bash final script action name
        success_only: True
      - before_message: This action will run on master node only when at least one action completed with FAILURE...
        action: run bash final script action name
        fail_only: True
        node:
          name: master
      - before_message: Running a downstream pipeline without getting file artifacts just to check handling.
        action: run downstream job action name
      - before_message: Running a downstream pipeline with getting unexisting artifacts file.
        action: run downstream job with incorrect artifacts file action name

  - name: report_stage
    actions:
      # Send all pipeline reports.
      - action: email report action name
      - action: mattermost report action name
      # Save formatted reports. This action will save only previous action and stages reports.
      - action: save formatted reports script action name
      # And finally archive them as pipeline file artifacts.
      - action: archive reports files as artifacts action name


# All possible kinds of actions set here.
actions:
  # Clone sources to `subdirectory_in_workspace_for_repository` then switch to the `main` branch.
  git_clone_action_name:
    repo_url: https://github.com/alexanderbazhenoff/ansible-collection-linux.git
    repo_branch: main
    directory: subdirectory_in_workspace_for_repository

  # Install an ansible collections from Ansible Galaxy.
  ansible_galaxy_install_action_name:
    collections:
      - community.postgresql
      - alexanderbazhenoff.linux

  # Install a single ansible collection from Ansible Galaxy. This collection installation is just an example of how to
  # set a single collection value in string format, because it's not required for the whole pipeline tun.
  ansible_galaxy_install_action_name_2:
    collections: community.docker

  # Actions that run ansible playbooks.
  show ansible hostname action name:
    playbook: ping_playbook_name

  install lxc action name:
    playbook: run_role_playbook_name

  # Run `downstream-example-pipeline` and pass `DOWNSTREAM_JOB_PARAMETER_1` with `PERFORM_PING` upstream pipeline
  # parameter value and `EMAIL` with `$EMAIL` value. Do not propagate errors of a downstream pipeline, but wait for the
  # completion. Finally, copy `test_file.txt` to `downstream_job_artifacts_folder_name` folder in workspace of
  # `downstream-example-pipeline` as artifacts, but ignore when this file is absent. Fingerprints are also enabled.
  run downstream job with artifacts action name:
    pipeline: $DOWNSTREAM_PIPELINE_NAME
    parameters:
      # Take a look at value pass: you should pass a value as `$FOO` for boolean parameter.
      - name: DOWNSTREAM_JOB_PARAMETER_1
        type: boolean
        value: $PERFORM_PING
      - name: DOWNSTREAM_JOB_PARAMETER_2
        type: text
        value: $multilineReport
      - name: EMAIL
        type: string
        value: $EMAIL
    propagate: False
    copy_artifacts:
      filter: test_file.txt
      fingerprint: True
      target_directory: subdirectory_in_workspace_for_repository
      optional: True

  # Run a downstream pipeline with getting unexisting artifacts file just to show error handling.
  run downstream job with incorrect artifacts file action name:
    pipeline: $DOWNSTREAM_PIPELINE_NAME
    parameters:
      - name: DOWNSTREAM_JOB_PARAMETER_1
        type: boolean
        value: $PERFORM_PING
      - name: DOWNSTREAM_JOB_PARAMETER_2
        type: text
        value: $multilineReport
      - name: EMAIL
        type: string
        value: $EMAIL
    propagate: False
    copy_artifacts:
      filter: no_such_file.txt

  # Run a downstream pipeline just to test is it possible to skip getting artifacts.
  run downstream job action name:
    pipeline: $DOWNSTREAM_PIPELINE_NAME
    parameters:
      - name: DOWNSTREAM_JOB_PARAMETER_1
        type: boolean
        value: $PERFORM_PING
      - name: DOWNSTREAM_JOB_PARAMETER_2
        type: text
        value: $multilineReport
      - name: EMAIL
        type: string
        value: $EMAIL


  # Stash any file in any subdirectory of `subdirectory_in_workspace_for_repository` folder in workspace with
  # `stash_name` naming.
  stash files action name:
    stash: stash_name
    includes: subdirectory_in_workspace_for_repository/**/*

  # Unstash files and folders with stash name `stash_name`.
  unstash files action name:
    unstash: stash_name

  # Archive as pipeline artifact any file from cloned from a git ansible collection, including unexisting file
  # `test_file.txt`, but except markdown files inside the roles. Do not fail the whole pipeline execution on unexisting
  # `test_file.txt` file.
  archive artifacts action name:
    artifacts: |
      subdirectory_in_workspace_for_repository/roles/**/*.*, subdirectory_in_workspace_for_repository/test_file.txt
    excludes: subdirectory_in_workspace_for_repository/roles/**/*.md

  # Archive the content of `settings` directory as pipeline artifact. There's no path specified, action already started
  # in `settings` directory.
  archive additional artifacts action name:
    artifacts: '*.*'

  # Archive reports artifacts.
  archive reports files as artifacts action name:
    artifacts: 'actions_report.txt, stages_report.txt'

  # Actions to run scripts.
  run custom code as a part of pipeline action name:
    script: script_name_1

  run bash script action name:
    script: script_name_2

  # Action that sends email report with a name of the pipeline, overall pipeline status, URL to console and
  # stages and actions report table.
  email report action name:
    report: email
    to: $EMAIL
    reply_to: $EMAIL
    subject: Test email report
    body: |
      Hi,

      I've just run a test for universal jenkins wrapper pipeline for '$JOB_NAME' pipeline, finished with
      '$currentBuild_result' state. As you see sending report to $EMAIL done.

      Overall report is:
      $multilineReport
      
      where failed actions are:
      $multilineReportFailed

      Check pipeline console for details: $BUILD_URL/console
      This report was generated automatically, please do not reply.

      Sincerely,
      Your Jenkins.

  # Action that sends mattermost report to mattermost.com using token with pipeline name and stages and actions report
  # table.
  mattermost report action name:
    report: mattermost
    # So paste your mattermost URL and working token like this, or set as global variable inside the libraries
    # (then set something like `$GlobalVariable`).
    url: https://mattermost.com/hooks/31895e09lg2m0g44dk4qeb847s
    text: |
      Hi, I've just run a test for universal jenkins wrapper pipeline: $JOB_NAME.
      Overall report is:
      
      ```
      $multilineReport
      ```
      
      Please ignore this automatic report.

  # Run a script that exits with error (but this will be ignored by setting up the key `ignore_fail` in `stages`).
  run bash final script action name:
    script: script_name_3

  save formatted reports script action name:
    script: save_formatted_reports_script_script_name


# All possible kinds of script running here.
scripts:

  # Run a code as a part of pipeline including code for Jenkins and Teamcity that will be selected in the appropriate
  # environment.
  script_name_1:
    pipeline: True
    jenkins: |
      // some groovy code here to print 'PIPELINE_ACTION' and 'EMAIL' pipeline parameters:
      println String.format('EMAIL provided for %s action is awesome: %s', env.PIPELINE_ACTION, env.EMAIL)
    teamcity: |
      // some kotlin code here to print 'PIPELINE_ACTION' and 'EMAIL' pipeline parameters:
      print (String.format("EMAIL provided for %s action is awesome: %s", env.PIPELINE_ACTION, env.EMAIL))

  script_name_2:
    # You can also set as a hashbang any environment that you want, e.g: `#!/usr/bin/env python`.
    script: |
      #!/usr/bin/env bash
      printf "Here is some output of LXCFS environment variable, which also a pipeline parameter: %s\n" "$LXCFS"
      printf "while the whole environment variables looks like: %s\n" "$(env)"

  script_name_3:
    # This bash script with error code shows you error handling in actions.
    script: |
      #!/usr/bin/env bash
      echo "All done, but exit 1."
      exit 1

  save_formatted_reports_script_script_name:
    # Save action and stage reports to text files.
    script: |
      #!/usr/bin/env bash
      echo "$multilineReport" > actions_report.txt
      echo "$multilineReportStages" > stages_report.txt


# Playbooks are here, where ansible ping will be skipped when `PERFORM_PING` pipeline parameter wasn't set.
playbooks:

  ping_playbook_name: |
    - hosts: all

      tasks:

        - name: "Perform ansible ping on the host(s) to show hosts"
          ansible.builtin.ping:
          when: $PERFORM_PING

  run_role_playbook_name: |
    - hosts: all
      become: True
      become_method: sudo
      gather_facts: True

      tasks:

        - name: "Perform ansible ping on the host(s) to show hosts"
          ansible.builtin.ping:
          when: $PERFORM_PING

        - name: "Install {{ $LXCFS | ternary ('lxcfs', 'lxc') }}"
          ansible.builtin.include_role:
            name: alexanderbazhenoff.linux.lxcfs
          vars:
            lxc_technology: "{{ $LXCFS | ternary ('lxcfs', 'lxc') }}"

# The only inventory for both playbooks is here.
inventories:

  default: |
    [all]
    $IP_ADDRESSES

    [all:vars]
    ansible_connection=ssh
    ansible_become_user=root
    ansible_ssh_common_args='-o StrictHostKeyChecking=no'
    ansible_ssh_user=$SSH_LOGIN
    ansible_ssh_pass=$SSH_PASSWORD
    ansible_become_pass=$SSH_SUDO_PASSWORD
